{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Machine learning is an application of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being individually programmed.\n",
    "\n",
    "2)Supervised learning is the process of learning an algorithm from the training dataset. Unsupervised learning is to find the structure and patterns from the input data. Unsupervised learning does not need any supervision. Instead, it finds patterns from the data on its own. \n",
    "Examples of supervised learning: Classification, regression, support vector machine\n",
    "Examples of unsupervised learning: Clustering, association, k-means\n",
    "\n",
    "3)Validation set is a set of examples used to tune the parameters of a classifier, for example to choose the number of hidden units in a neural network. Test set is a set of examples used only to assess the performance of a fully-specified classifier. Validation is used to determine the best performing algorithm, the test set is to put the algorithm through some tests to see how it will perform, so that we can have an idea about the algorithm's performance on unseen data. \n",
    "\n",
    "4) The main preprocessing steps are: data cleaning, data integration, data reduction, and data transformation. \n",
    "Data cleaning: Data cleaning refers to techniques to ‘clean’ data by removing outliers, replacing missing values, smoothing noisy data, and correcting inconsistent data.\n",
    "Data integration:Since data is being collected from multiple sources, data integration has become a vital part of the process. This may lead to redundant and inconsistent data, which could result in poor accuracy and speed of data model. To deal with these issues and maintain the data integrity, approaches such as tuple duplication detection and data conflict detection are sought after.\n",
    "Data reduction:The purpose of data reduction is to have a condensed representation of the data set which is smaller in volume, while maintaining the integrity of original. This results in efficient yet similar results.\n",
    "Data transformation:The final step of data preprocessing is transforming the data into form appropriate for data modeling\n",
    "\n",
    "5) Discrete data involves round, concrete numbers that are determined by counting. Continuous data involves complex numbers that are measured across a specific time interval. In other words, discrete data relates to countable items while continuous data involves concepts that are not simply countable but require detailed measurements.\n",
    "\n",
    "6) The type is a distplot, since the data is already visualized we need to standardize the data as the next step. After that we need to use principal component analysis (PCA) to reduce the size of the feature space while retaining as much of the information as possible, after that we use data splitting to finalize the preprocessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
